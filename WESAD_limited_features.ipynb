{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress Prediction all Models, Limited Features\n",
    "\n",
    "This notebook uses sensor measurements from the\n",
    "chest device: accelerometer data (ACC), temperature data \n",
    "(skin temperature), and electrodermal activity (EDA) aka galvanic skin response\n",
    "(GSR).\n",
    "\n",
    "The features of interest for the ACC data are as follows.\n",
    "\n",
    "1. mean for each axis; summed over all axes \n",
    "2. STD for each axis; summed over all axes \n",
    "2. Peak frequency for x\n",
    "3. Peak frequency for Y\n",
    "4. Peak frequency for z\n",
    "\n",
    "The features of interest for the temperature sensor are:\n",
    "\n",
    "1. Min value\n",
    "2. max value\n",
    "2. Dynamic Range\n",
    "4. Mean \n",
    "5. STD\n",
    "\n",
    "The features of interest for the EDA data are:\n",
    "\n",
    "1. Min value\n",
    "2. max value\n",
    "2. Dynamic Range\n",
    "4. Mean \n",
    "5. STD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.22.4)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->statsmodels) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.datasets import fetch_mldata\n",
    "import seaborn as sns\n",
    "import sklearn as sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "%pip install statsmodels \n",
    "import graphviz \n",
    "import statsmodels.api as sm\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.4)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dollj\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "%pip install pickle\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\dollj\\\\Documents\\\\Jupyter\\\\WESAD\\\\data\\\\WESAD\\\\S2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\github\\stress-affect-wesad\\WESAD_all_models.ipynb Cell 7\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/stress-affect-wesad/WESAD_all_models.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m s2_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdollj\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mJupyter\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWESAD\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWESAD\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/stress-affect-wesad/WESAD_all_models.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#s2_path = data_set + 'S2/S2.pkl'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/github/stress-affect-wesad/WESAD_all_models.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(s2_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/stress-affect-wesad/WESAD_all_models.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     s2_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\dollj\\\\Documents\\\\Jupyter\\\\WESAD\\\\data\\\\WESAD\\\\S2'"
     ]
    }
   ],
   "source": [
    "#data_set = r\"C:\\Users\\dollj\\Documents\\Jupyter\\WESAD\\data\\WESAD\\S2\"\n",
    "#data_set = r\"C:\\Users\\A\\Desktop\\neural networks\\WESAD-data\\S2\"\n",
    "s2_path = r\"C:\\Users\\dollj\\Documents\\Jupyter\\WESAD\\data\\WESAD\\S2\"\n",
    "#s2_path = data_set + 'S2/S2.pkl'\n",
    "\n",
    "\n",
    "with open(s2_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.shape)\n",
    "display(df.info)\n",
    "display(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean normalization \n",
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "#min-max normalization:\n",
    "#norm_df_out=(df_out-df_out.min())/(df_out.max()-df_out.min())\n",
    "\n",
    "norm_y = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train,norm_x_test,norm_y_train,norm_y_test=train_test_split(norm_x,norm_y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = norm_x.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_1 = sm.add_constant(norm_x)\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(norm_y,X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b\n",
    "#https://towardsdatascience.com/feature-selection-using-wrapper-methods-in-python-f0d352b346f\n",
    "\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# Sequential Forward Selection(sfs)\n",
    "sfs = SFS(QuadraticDiscriminantAnalysis(),\n",
    "           k_features=7,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           scoring = 'r2',\n",
    "           cv = 0)\n",
    "sfs.fit(norm_x, norm_y)\n",
    "sfs.k_feature_names_     # to get the final set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SFS(QuadraticDiscriminantAnalysis(),\n",
    "           k_features=7,\n",
    "           forward=False,\n",
    "           floating=False,\n",
    "           scoring = 'r2',\n",
    "           cv = 0)\n",
    "sfs.fit(norm_x, norm_y)\n",
    "sfs.k_feature_names_     # to get the final set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=df_out.w_label\n",
    "x=df_out.drop('w_label',axis=1)\n",
    "#print(x)\n",
    "#print(\"\\n-----\\n\")\n",
    "#print(y)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl_lm.LogisticRegression(solver='newton-cg',penalty='none')\n",
    "clf.fit(x_train,y_train)\n",
    "y_out = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_out, digits=4))\n",
    "\n",
    "'''\n",
    "(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=3,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False) or use slover=saga\n",
    "'''                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression + L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl_lm.LogisticRegression(solver='newton-cg',penalty='l2',multi_class='auto')\n",
    "clf.fit(x_train,y_train)\n",
    "y_out = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_out, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl_lm.LogisticRegression(solver='newton-cg',penalty='l2',multi_class='auto')\n",
    "y_out = cross_val_predict(clf, norm_x, norm_y, cv=5)\n",
    "print(classification_report(norm_y_test, y_out, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Basic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA= LinearDiscriminantAnalysis(solver = 'svd')\n",
    "y_out = LDA.fit(x_train, y_train).predict(x_test)\n",
    "#confusion_matrix(y_test, y_out)\n",
    "print(classification_report(y_test, y_out, digits=4))#target_names=['Not Six', 'Six']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA + Normalization + n_components &  5 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA= LinearDiscriminantAnalysis(solver = 'svd')\n",
    "#norm_y_out = LDA.fit(norm_x_train, norm_y_train).predict(norm_x_test)\n",
    "norm_y_out = cross_val_predict(LDA, norm_x, norm_y, cv=5)\n",
    "print(classification_report(norm_y_test, norm_y_out, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA Basic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "qda_clf.fit(x_train,y_train)\n",
    "y_out = qda_clf.fit(x_train, y_train).predict(x_test)\n",
    "print(classification_report(y_test, y_out, digits=4))#target_names=['Not Six', 'Six']\n",
    "#IF QDA is best, then data must be Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=5)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA + Normalization + Cross Validation = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST MODEL *****++++****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)\n",
    "'''\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.5)\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.9)\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.7)\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA + Normalization + Cross Validation = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "norm_y_out = cross_val_predict(qda_clf, norm_x, norm_y, cv=20)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lm=(classification_report(y, y_out, digits=4))\n",
    "print(lm)\n",
    "scores = cross_val_score(qda_clf, x, y, cv=10, scoring='accuracy').mean()\n",
    "print(scores)\n",
    "\n",
    "#scoring='mean_squared_error'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "y_out = cross_val_predict(qda_clf, x, y, cv=loo)\n",
    "lm=(classification_report(y, y_out, digits=4))\n",
    "lm=(classification_report(y, y_out, digits=4))\n",
    "print(lm)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation + K=3 + Normalization [ CV = 10, K = 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do base mdel with test and train data, show improvement in next section with cross validation\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)\n",
    "#https://www.ritchieng.com/machine-learning-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation + K=5 + Normalization [ CV = 20, K = 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=20)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation + K=10 + Normalization [ CV = 10, K = 10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation [ CV = 10, K = 20 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation [ CV = 10, K = 30 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation [ CV = 10, K = 40 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=40)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation [ CV = 10, K = 60 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=60)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + Cross Validation [ CV = 10, K = 100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "norm_y_out = cross_val_predict(knn, norm_x, norm_y, cv=10)\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree + Depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "\n",
    "clf_i = clf.fit(x_train,y_train)\n",
    "\n",
    "y_out_i = clf_i.predict(x_test)\n",
    "\n",
    "lm_i=(classification_report(y_test, y_out_i, digits=4))\n",
    "print(lm_i)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying and Drwaing the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "features_ax=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\"]\n",
    "classes_ay=['0', '1', '2', '3', '4']\n",
    "\n",
    "dot_data = tree.export_graphviz(clf_i, out_file=None, \n",
    "                      feature_names=features_ax,  \n",
    "                      class_names=classes_ay,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"Decision_tree\")\n",
    "graph \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree + Depth = 5 + Cross Validation + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "\n",
    "\n",
    "norm_y_out = cross_val_predict(clf, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree + Depth = 7 + Normalization + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=7)\n",
    "\n",
    "norm_y_out = cross_val_predict(clf, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Decision Tree + Normalization + Cross Validation\n",
    "\n",
    "## Criterion = Gini, Max_depth = 5, CV = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=5)\n",
    "\n",
    "norm_y_out = cross_val_predict(clf, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Implementation \n",
    "\n",
    "## Normalization + max_depth = 10, alpha = 10, n_estimators = 50, gamma=10\n",
    "\n",
    "## colsample_bytree = 0.3, learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d\n",
    "#https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "#https://medium.com/@gabrielziegler3/multiclass-multilabel-classification-with-xgboost-66195e4d9f2d\n",
    "\n",
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "xg_class.fit(x_train,y_train)\n",
    "\n",
    "y_out = xg_class.predict(x_test)\n",
    "\n",
    "lm_xgb=(classification_report(y_test, y_out, digits=4))\n",
    "\n",
    "print(lm_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "\n",
    "norm_y_out = cross_val_predict(xg_class, norm_x, norm_y, cv=5)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "\n",
    "norm_y_out = cross_val_predict(xg_class, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Implementation \n",
    "\n",
    "## Normalization + max_depth = 5, alpha = 10, n_estimators = 20, gamma=20\n",
    "\n",
    "## colsample_bytree = 0.3, learning_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.9,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 20, gamma=20)\n",
    "\n",
    "\n",
    "norm_y_out = cross_val_predict(xg_class, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 15, alpha = 10, n_estimators = 70, gamma=10)\n",
    "\n",
    "\n",
    "norm_y_out = cross_val_predict(xg_class, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVC classifier using a linear kernel\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C=1, random_state=0)\n",
    "# Train the classifier\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_out = clf.predict(x_test)\n",
    "lm_svc=(classification_report(y_test, y_out, digits=4))\n",
    "print(lm_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + Normalization + Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://scikit-learn.org/stable/modules/svm.html\n",
    "#https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "#https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769\n",
    "###https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "#https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/\n",
    "\n",
    "#svm = SVC(kernel='rbf', random_state=0, gamma=10, C=1)\n",
    "#1000 iterations take 25 minutes\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf', random_state=0, gamma=10, C=100,\n",
    "              shrinking=True, tol=1.000, cache_size=10) ##(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_out = clf.predict(x_test)\n",
    "lm_svc=(classification_report(y_test, y_out, digits=4))\n",
    "print(lm_svc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + Normalization + Cross Validation + Gamma = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf', random_state=0, gamma=20, C=100,\n",
    "              shrinking=True, tol=1.000, cache_size=10) ##(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(norm_x_train, norm_y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "norm_y_out = clf.predict(norm_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_svm=(classification_report(norm_y_test, norm_y_out, digits=4))\n",
    "print(lm_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y_out = cross_val_predict(clf, norm_x, norm_y, cv=10)\n",
    "\n",
    "lm=(classification_report(norm_y, norm_y_out, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Implementation with 4 features + KNN + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python\n",
    "\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "x_pca=pca.fit_transform(x)\n",
    "#x_pca = pca.transform(x_pca)\n",
    "print(\"original shape:   \", x.shape)\n",
    "print(\"transformed shape:\", x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data=x_pca, columns=[\"PCA-1\", \"PCA-2\", \"PCA-3\",\"PCA-4\"]) \n",
    "pca_df['w_label'] = y.values\n",
    "print(\"data frame combined\",min(y),max(y))\n",
    "print(pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pca_df.head())\n",
    "#print(pca_df[\"w_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_y = pca_df.w_label\n",
    "pca_x = pca_df.drop('w_label',axis=1)\n",
    "\n",
    "pca_x_train,pca_x_test, pca_y_train, pca_y_test = train_test_split(pca_x,pca_y,test_size=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 4 features + Simple Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(pca_x_train, pca_y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "pca_y_out = clf.predict(pca_x_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_out))\n",
    "lmIV=(classification_report(pca_y_test, pca_y_out, digits=4))\n",
    "print(lmIV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 4 features + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "pca_y_out = cross_val_predict(knn, pca_x, pca_y, cv=20)\n",
    "lm=(classification_report(pca_y, pca_y_out, digits=4))\n",
    "#https://www.ritchieng.com/machine-learning-cross-validation/\n",
    "lm=(classification_report(pca_y, pca_y_out, digits=4))\n",
    "print(lm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 4 features + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "xg_class.fit(pca_x_train,pca_y_train)\n",
    "\n",
    "pca_y_out = xg_class.predict(pca_x_test)\n",
    "\n",
    "lm_xgbIV=(classification_report(pca_y_test, pca_y_out, digits=4))\n",
    "\n",
    "print(lm_xgbIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 1 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_1 = pca_df_2.drop('PCA-2',axis=1)\n",
    "print(pca_df_1.head())\n",
    "\n",
    "pca_y = pca_df_1.w_label\n",
    "pca_x = pca_df_1.drop('w_label',axis=1)\n",
    "\n",
    "pca_x_trainI,pca_x_testI, pca_y_trainI, pca_y_testI = train_test_split(pca_x,pca_y,test_size=0.2)\n",
    "pca_x_trainI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 1 feature + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "xg_class.fit(pca_x_trainI,pca_y_trainI)\n",
    "\n",
    "pca_y_outI = xg_class.predict(pca_x_testI)\n",
    "\n",
    "lm_xgbI=(classification_report(pca_y_testI, pca_y_outI, digits=4))\n",
    "\n",
    "print(lm_xgbI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 2 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_2 = pca_df_3.drop('PCA-3',axis=1)\n",
    "print(pca_df_2.head())\n",
    "pca_y = pca_df_2.w_label\n",
    "pca_x = pca_df_2.drop('w_label',axis=1)\n",
    "\n",
    "pca_x_trainII,pca_x_testII, pca_y_trainII, pca_y_testII = train_test_split(pca_x,pca_y,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(pca_x_trainII, pca_y_trainII)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "pca_y_outII = clf.predict(pca_x_testII)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_out))\n",
    "lm=(classification_report(pca_y_testII, pca_y_outII, digits=4))\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 2 features + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "xg_class.fit(pca_x_trainII,pca_y_trainII)\n",
    "\n",
    "pca_y_outII = xg_class.predict(pca_x_testII)\n",
    "\n",
    "lm_xgbII=(classification_report(pca_y_testII, pca_y_outII, digits=4))\n",
    "\n",
    "print(lm_xgbII)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_3 = pca_df.drop('PCA-4',axis=1)\n",
    "\n",
    "print(pca_df_3.head())\n",
    "pca_y = pca_df_3.w_label\n",
    "pca_x = pca_df_3.drop('w_label',axis=1)\n",
    "\n",
    "pca_x_trainIII,pca_x_testIII, pca_y_trainIII, pca_y_testIII = train_test_split(pca_x,pca_y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with 3 features + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class = xgb.XGBClassifier(objective ='multi:softmax', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, gamma=10)\n",
    "\n",
    "xg_class.fit(pca_x_trainIII,pca_y_trainIII)\n",
    "\n",
    "pca_y_outIII = xg_class.predict(pca_x_testIII)\n",
    "\n",
    "lm_xgbIII=(classification_report(pca_y_testIII, pca_y_outIII, digits=4))\n",
    "\n",
    "print(lm_xgbIII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING BEST MODEL ON 7 SUBJECTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3_path = data_set + 'S3/S3.pkl'\n",
    "\n",
    "with open(s3_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated_3\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_3 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_3 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_3,norm_x_test_3,norm_y_train_3,norm_y_test_3=train_test_split(norm_x_3,norm_y_3,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_3 = cross_val_predict(qda_clf, norm_x_3, norm_y_3, cv=10)\n",
    "lm_3=(classification_report(norm_y_3, norm_y_out_3, digits=4))\n",
    "print(lm_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s4_path = data_set + 'S4/S4.pkl'\n",
    "\n",
    "with open(s4_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_4 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_4 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_4,norm_x_test_4,norm_y_train_4,norm_y_test_4=train_test_split(norm_x_4,norm_y_4,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_4 = cross_val_predict(qda_clf, norm_x_4, norm_y_4, cv=10)\n",
    "lm_4=(classification_report(norm_y_4, norm_y_out_4, digits=4))\n",
    "print(lm_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s10_path = data_set + 'S10/S10.pkl'\n",
    "\n",
    "with open(s10_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_10 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_10 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_10,norm_x_test_10,norm_y_train_10,norm_y_test_10=train_test_split(norm_x_10,norm_y_10,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_10 = cross_val_predict(qda_clf, norm_x_10, norm_y_10, cv=10)\n",
    "lm_10=(classification_report(norm_y_10, norm_y_out_10, digits=4))\n",
    "print(lm_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s11_path = data_set + 'S11/S11.pkl'\n",
    "\n",
    "with open(s11_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_11 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_11 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_11,norm_x_test_11,norm_y_train_11,norm_y_test_11=train_test_split(norm_x_11,norm_y_11,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_11 = cross_val_predict(qda_clf, norm_x_11, norm_y_11, cv=10)\n",
    "lm_11=(classification_report(norm_y_11, norm_y_out_11, digits=4))\n",
    "print(lm_11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s16_path = data_set + 'S16/S16.pkl'\n",
    "\n",
    "with open(s16_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_16 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_16 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_16,norm_x_test_16,norm_y_train_16,norm_y_test_16=train_test_split(norm_x_16,norm_y_16,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_16 = cross_val_predict(qda_clf, norm_x_16, norm_y_16, cv=10)\n",
    "lm_16=(classification_report(norm_y_16, norm_y_out_16, digits=4))\n",
    "print(lm_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s17_path = data_set + 'S17/S17.pkl'\n",
    "\n",
    "with open(s17_path, 'rb') as file:\n",
    "    s2_data = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "c_ax=s2_data['signal']['chest']['ACC'][0:,0]#[baseline_to_plot]\n",
    "c_ay=s2_data['signal']['chest']['ACC'][0:,1]#[baseline_to_plot]#[0:100] # hundred values\n",
    "c_az=s2_data['signal']['chest']['ACC'][0:,2]#[baseline_to_plot]\n",
    "c_ecg=s2_data['signal']['chest']['ECG'][:,0]#[baseline_to_plot]\n",
    "c_emg=s2_data['signal']['chest']['EMG'][:,0]#[baseline_to_plot]\n",
    "c_eda=s2_data['signal']['chest']['EDA'][:,0]#[baseline_to_plot]\n",
    "c_temp=s2_data['signal']['chest']['Temp'][:,0]#[baseline_to_plot]\n",
    "c_resp=s2_data['signal']['chest']['Resp'][:,0]#[baseline_to_plot]\n",
    "w_ax=s2_data['signal']['wrist']['ACC'][0:,0]#[stress_to_plot]\n",
    "w_ay=s2_data['signal']['wrist']['ACC'][0:,1]#[stress_to_plot]\n",
    "w_az=s2_data['signal']['wrist']['ACC'][0:,2]#[stress_to_plot]\n",
    "w_bvp=s2_data['signal']['wrist']['BVP'][:,0]#[stress_to_plot]\n",
    "w_eda=s2_data['signal']['wrist']['EDA'][:,0]#[stress_to_plot]\n",
    "w_temp=s2_data['signal']['wrist']['TEMP'][:,0]#[stress_to_plot]\n",
    "w_label=s2_data['label']\n",
    "\n",
    "print(\"Equated\")    \n",
    "\n",
    "numpy_data1=np.array([c_ax, c_ay, c_az,c_ecg,c_emg,c_eda,c_temp,c_resp,w_label])\n",
    "numpy_data1=numpy_data1.T\n",
    "\n",
    "#df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_ax\",\"w_ay\",\"w_az\",\"w_bvp\",\"w_eda\",\"w_temp\"],orient='index') \n",
    "df = pd.DataFrame(data=numpy_data1, columns=[\"c_ax\", \"c_ay\", \"c_az\",\"c_ecg\",\"c_emg\",\"c_eda\",\"c_temp\",\"c_resp\",\"w_label\"]) \n",
    "\n",
    "print(\"data frame combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR is\\n\", IQR)\n",
    "#print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)) )\n",
    "df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_out=(df_out-df_out.mean())/df_out.std()\n",
    "\n",
    "norm_y_17 = df_out.w_label #keep original labels Dont normalize labels\n",
    "norm_x_17 = norm_df_out.drop('w_label',axis=1)\n",
    "\n",
    "\n",
    "norm_x_train_17,norm_x_test_17,norm_y_train_17,norm_y_test_17=train_test_split(norm_x_17,norm_y_17,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0)\n",
    "norm_y_out_17 = cross_val_predict(qda_clf, norm_x_17, norm_y_17, cv=10)\n",
    "lm_17=(classification_report(norm_y_17, norm_y_out_17, digits=4))\n",
    "print(lm_17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b8214bdbcddfe95913c8e726854c2e6f782bd26473edb6d5d1c1ac13615c051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
